# Vision Document - Telegram LLM Bot для оценки IT задач

> **Цель**: Создать максимально простое решение для проверки идеи LLM-ассистента в виде Telegram-бота для оценивания задач IT сотрудников.
> 
> **Принципы**: KISS, ООП (1 класс = 1 файл), никакого оверинжиниринга.

---

## 1. Технологии

### Core технологии
- **Python 3.x** - основной язык (версия установленная на системе)
- **uv** - управление зависимостями и виртуальным окружением (pyproject.toml)
- **aiogram 3.x** - для Telegram Bot API (polling)
- **openai** - Python client для работы с LLM через Openrouter
- **make** - автоматизация задач (setup, run, clean)

### Дополнительные библиотеки
- **python-dotenv** - загрузка переменных окружения из .env
- **pydantic** - валидация конфигурации
- **logging** (встроенный) - логирование

### Что НЕ используем (избегаем оверинжиниринга)
- ❌ Базы данных (только in-memory хранение)
- ❌ Redis/кэширование
- ❌ Веб-интерфейсы/дашборды
- ❌ Docker (на первом этапе)
- ❌ Системы мониторинга

---

## 2. Принципы разработки

### Основные принципы
- **KISS** (Keep It Simple, Stupid) - максимальная простота
- **ООП** - один класс на один файл (строго)
- **Никакого оверинжиниринга** - только необходимый функционал
- **Читаемость > умность кода** - код должен быть понятен
- **Fail-fast** - быстрое падение при ошибках конфигурации

### Правила кодирования
- Один класс = один файл (строго)
- Явное лучше неявного
- Минимум абстракций
- Строгая типизация через type hints (с проверкой mypy)
- Docstrings для классов и публичных методов
- Использование линтера/форматтера (ruff/black)

### Что НЕ делаем
- ❌ Сложные паттерны проектирования
- ❌ Излишнюю абстракцию
- ❌ Преждевременную оптимизацию
- ❌ Многослойную архитектуру

### Подход к тестированию
- Unit-тесты НЕ на первом этапе
- Добавим после проверки идеи

---

## 3. Структура проекта

```
TEARepo/
├── src/
│   ├── bot/
│   │   ├── __init__.py
│   │   ├── telegram_bot.py          # TelegramBot - главный класс бота
│   │   └── message_handler.py       # MessageHandler - обработка сообщений
│   ├── llm/
│   │   ├── __init__.py
│   │   ├── llm_client.py            # LLMClient - работа с OpenRouter
│   │   └── conversation.py          # Conversation - хранение истории диалога
│   ├── config/
│   │   ├── __init__.py
│   │   └── settings.py              # Settings - конфигурация приложения
│   └── main.py                      # Точка входа
├── logs/
│   ├── app.log                      # Основной лог
│   └── errors.log                   # Лог ошибок
├── docs/
│   ├── idea.md
│   └── vision.md
├── .env                             # Конфигурация (НЕ в git)
├── .env.example                     # Пример конфигурации
├── .gitignore
├── pyproject.toml                   # Зависимости (uv)
├── Makefile                         # Команды автоматизации
└── README.md
```

### Описание структуры
- **src/** - весь исходный код
- **src/bot/** - логика Telegram бота (2 класса)
- **src/llm/** - работа с LLM и контекст диалогов (2 класса)
- **src/config/** - конфигурация (1 класс)
- **logs/** - файлы логов
- **main.py** - запуск приложения

**Итого: 5 классов для MVP**

---

## 4. Архитектура проекта

### Диаграмма компонентов

```
┌─────────────────┐
│  Telegram Bot   │  <- Входная точка (aiogram polling)
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Message Handler │  <- Обработка команд и сообщений
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│   LLM Client    │  <- Работа с OpenRouter API
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  Conversation   │  <- In-memory история диалогов
└─────────────────┘
```

### Компоненты и их ответственность

#### 1. TelegramBot (bot/telegram_bot.py)
- Инициализация aiogram
- Запуск polling
- Регистрация handlers

#### 2. MessageHandler (bot/message_handler.py)
- Обработка команд (/start, /help)
- Обработка текстовых сообщений
- Отправка ответов пользователю

#### 3. LLMClient (llm/llm_client.py)
- Подключение к OpenRouter через openai client
- Отправка запросов с системным промптом
- Получение ответов от LLM

#### 4. Conversation (llm/conversation.py)
- Хранение истории сообщений по user_id
- Управление контекстом диалога
- Ограничение размера истории (20 сообщений = 10 пар)

#### 5. Settings (config/settings.py)
- Загрузка конфигурации из .env
- Валидация через Pydantic
- Предоставление настроек

### Поток данных

1. Пользователь → Telegram
2. Telegram → TelegramBot (polling)
3. TelegramBot → MessageHandler
4. MessageHandler → Conversation (получение истории)
5. MessageHandler → LLMClient (запрос с историей)
6. LLMClient → OpenRouter API
7. OpenRouter → LLMClient (ответ)
8. LLMClient → MessageHandler
9. MessageHandler → Conversation (сохранение)
10. MessageHandler → Telegram (ответ пользователю)

### Параметры
- **Ограничение истории**: 10 пар вопрос-ответ (20 сообщений)
- **Таймаут LLM**: 30 секунд
- **Команда /reset**: НЕТ (не нужна для MVP)

---

## 5. Модель данных

### In-memory хранение (без БД)

#### Message (сообщение в диалоге)
```python
{
    "role": str,        # "system" | "user" | "assistant"
    "content": str      # текст сообщения
}
```

#### ConversationHistory (история диалога)
```python
{
    user_id: int -> List[Message]  # словарь user_id -> список сообщений
}
```

#### Settings (конфигурация через Pydantic)
```python
{
    # Telegram
    telegram_token: str              # Telegram Bot API токен (обязательно)
    
    # OpenRouter
    openrouter_api_key: str          # OpenRouter API ключ (обязательно)
    openrouter_model: str            # Модель LLM (default: "openai/gpt-3.5-turbo")
    
    # Application
    max_history_messages: int        # Макс. сообщений в истории (default: 20)
    llm_timeout: int                 # Таймаут запроса к LLM (default: 30)
    log_level: str                   # Уровень логирования (default: "INFO")
}
```

### Особенности
- **Хранение в памяти** - словарь Python (dict)
- **Потеря данных при перезапуске** - это OK для MVP
- **Нет персистентности** - максимальная простота
- **Формат OpenAI** - совместимость с openai client
- **Системный промпт** - hardcode в коде
- **Timestamp** - не храним для MVP

---

## 6. Работа с LLM

### Конфигурация интеграции
- **Библиотека**: `openai` Python client
- **Провайдер**: OpenRouter (OpenAI-compatible API)
- **Базовый URL**: `https://openrouter.ai/api/v1`
- **Модель по умолчанию**: `openai/gpt-3.5-turbo`

### Настройки LLMClient
- API ключ из .env (`OPENROUTER_API_KEY`)
- Модель из .env с дефолтом (`OPENROUTER_MODEL`)
- Таймаут: 30 секунд
- Retry логика: НЕТ (fail-fast)
- Дополнительные headers: пока НЕТ

### Формат запроса к API
```python
messages = [
    {"role": "system", "content": "Ты помощник для оценивания задач для IT сотрудников"},
    {"role": "user", "content": "..."},
    {"role": "assistant", "content": "..."},
    # ... история диалога (до 20 сообщений)
    {"role": "user", "content": "новое сообщение"}
]
```

### Параметры генерации
```python
temperature: 0.7          # Баланс креативности/точности
max_tokens: None          # Не ограничиваем (используем дефолт модели)
stream: False             # Простой запрос-ответ
```

### Системный промпт (hardcode)
```
"Ты помощник для оценивания задач для IT сотрудников"
```

### Обработка ошибок
- **Timeout** → логируем ERROR, отправляем пользователю "Превышено время ожидания"
- **API Error** → логируем ERROR, отправляем "Ошибка при обращении к LLM"
- **Network Error** → логируем ERROR, отправляем "Ошибка сети"

---

## 7. Сценарии работы

### 1. Первый запуск бота
```
Пользователь → /start
Бот → Приветственное сообщение + краткая инструкция
```
*Текст приветствия определим при разработке*

### 2. Получение помощи
```
Пользователь → /help
Бот → Список доступных команд и описание работы
```

### 3. Основной диалог (оценка задач)
```
Пользователь → "Нужно сделать REST API для управления пользователями"
Бот → Получает историю диалога (до 20 сообщений)
Бот → Отправляет запрос в LLM с системным промптом
Бот → Сохраняет обмен в историю
Бот → Отправляет ответ пользователю с оценкой
```

### 4. Продолжение диалога с контекстом
```
Пользователь → "А если добавить аутентификацию?"
Бот → Использует контекст предыдущих 10 пар сообщений
Бот → Дает уточненную оценку с учетом контекста
```

### 5. Обработка ошибок
```
Ошибка LLM → Бот отправляет понятное сообщение об ошибке
Ошибка сети → Бот логирует и уведомляет пользователя
Таймаут → Бот логирует и уведомляет о превышении времени
```

### Команды бота
- `/start` - запуск и приветствие
- `/help` - справка по использованию

### Возможности MVP
- ✅ Текстовые сообщения
- ✅ Контекст диалога (10 пар)
- ✅ Работа с LLM через OpenRouter
- ✅ Базовая обработка ошибок

### Ограничения MVP
- ❌ Нет мультимодальности (только текст)
- ❌ Нет команды /reset
- ❌ Нет настройки промпта пользователем
- ❌ Нет истории между перезапусками
- ❌ Нет rate limiting
- ❌ Нет команды для информации о модели
- ❌ Нет индикатора "печатает..."

---

## 8. Подход к конфигурированию

### Структура конфигурации

**Файл .env (не в git):**
```bash
# Telegram Bot
TELEGRAM_BOT_TOKEN=your_telegram_token_here

# OpenRouter LLM
OPENROUTER_API_KEY=your_openrouter_key_here
OPENROUTER_MODEL=openai/gpt-3.5-turbo

# Application
MAX_HISTORY_MESSAGES=20
LLM_TIMEOUT=30
LOG_LEVEL=INFO
```

**Файл .env.example (в git):**
```bash
# Telegram Bot
TELEGRAM_BOT_TOKEN=

# OpenRouter LLM
OPENROUTER_API_KEY=
OPENROUTER_MODEL=openai/gpt-3.5-turbo

# Application
MAX_HISTORY_MESSAGES=20
LLM_TIMEOUT=30
LOG_LEVEL=INFO
```

### Реализация Settings класса

**Технология**: Pydantic Settings

**Логика загрузки**:
1. python-dotenv загружает .env при старте
2. Pydantic Settings создает экземпляр с валидацией
3. Fail-fast при отсутствии обязательных полей
4. Использование дефолтных значений для опциональных полей

**Обязательные поля**:
- `TELEGRAM_BOT_TOKEN`
- `OPENROUTER_API_KEY`

**Опциональные поля** (с дефолтами):
- `OPENROUTER_MODEL` (default: "openai/gpt-3.5-turbo")
- `MAX_HISTORY_MESSAGES` (default: 20)
- `LLM_TIMEOUT` (default: 30)
- `LOG_LEVEL` (default: "INFO")

**Валидация**:
- Минимальная валидация (проверка на непустое значение)
- Проверка типов через Pydantic
- Понятные ошибки при неправильной конфигурации

**Системный промпт**:
- Hardcode в коде (не в .env)
- Значение: "Ты помощник для оценивания задач для IT сотрудников"

### Безопасность
- `.env` в `.gitignore` (секреты не попадают в репозиторий)
- `.env.example` без реальных токенов (только шаблон)
- Токены и ключи не логируются

---

## 9. Подход к логгированию

### Конфигурация

**Модуль**: стандартный `logging` Python

**Настройка**:
- Уровень из .env (`LOG_LEVEL`: DEBUG/INFO/WARNING/ERROR)
- Формат: текстовый, понятный для чтения
- Вывод: stdout (консоль) + файлы в `logs/`

### Структура файлов
```
logs/
  ├── app.log       # Все логи
  └── errors.log    # Только ERROR и выше
```

**Ротация**: НЕТ (для MVP не нужна)

### Формат сообщений
```
%(asctime)s - %(name)s - %(levelname)s - %(message)s
```

**Пример**:
```
2025-10-10 15:30:45 - bot.telegram_bot - INFO - Bot started
```

### Что логируем по уровням

#### INFO уровень
- Старт/остановка бота
- Получение сообщений от пользователей (user_id + полный текст)
- Успешные запросы к LLM
- Отправка ответов пользователям

#### WARNING уровень
- Достижение лимита истории сообщений
- Медленные ответы LLM (> 20 сек)

#### ERROR уровень
- Ошибки API (Telegram, OpenRouter)
- Таймауты запросов
- Ошибки сети
- Ошибки конфигурации

#### DEBUG уровень
- Полный текст сообщений
- Полные запросы/ответы LLM
- Детали работы каждого компонента

### Безопасность
- ❌ НЕ логируем токены и API ключи
- ❌ НЕ логируем sensitive данные
- ✅ Логируем полный текст сообщений пользователей на INFO уровне

---

## Итого: MVP характеристики

### Размер проекта
- **Классов**: 5
- **Файлов кода**: ~7 (с __init__.py)
- **Зависимостей**: 4 основные (aiogram, openai, pydantic, python-dotenv)

### Возможности
- ✅ Telegram бот (polling)
- ✅ Интеграция с LLM через OpenRouter
- ✅ Контекст диалога (10 пар сообщений)
- ✅ Базовая обработка ошибок
- ✅ Логирование
- ✅ Конфигурация через .env

### Ограничения
- ❌ Нет персистентности (in-memory)
- ❌ Нет БД
- ❌ Нет сложных команд
- ❌ Нет мультимодальности
- ❌ Нет rate limiting

### Принципы реализации
- **KISS** - максимальная простота
- **ООП** - 1 класс = 1 файл
- **Fail-fast** - быстрое падение при ошибках
- **Типизация** - строгие type hints
- **Читаемость** - понятный код

---

**Этот документ является техническим проектом и отправной точкой для разработки MVP.**

